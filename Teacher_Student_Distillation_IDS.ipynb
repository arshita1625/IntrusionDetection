{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Teacher-Student Distillation for Intrusion Detection Autoencoder\n","This notebook builds on the dropout autoencoder (teacher) and trains a smaller student model to mimic the teacher’s outputs, improving generalization."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Step 1: Imports\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Step 2: Load & Prepare Data\n","df = pd.read_csv(\"UNSW-NB15P-MM-SAMPLE.csv\")\n","Dn = df[df.Class == 0].drop(columns='Class')\n","Da = df[df.Class == 1].drop(columns='Class')\n","Dntr, Dnts = train_test_split(Dn, test_size=0.2, random_state=42)\n","Dts = pd.concat([Dnts, Da], ignore_index=True)\n","y_test = np.array([0]*len(Dnts) + [1]*len(Da))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Step 3: Normalize\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(Dntr)\n","X_test = scaler.transform(Dts)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - loss: 0.6091 - val_loss: 0.2343\n","Epoch 2/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - loss: 0.3159 - val_loss: 0.1891\n","Epoch 3/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - loss: 0.2684 - val_loss: 0.1624\n","Epoch 4/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - loss: 0.2493 - val_loss: 0.1450\n","Epoch 5/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - loss: 0.2307 - val_loss: 0.1448\n","Epoch 6/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - loss: 0.2254 - val_loss: 0.1410\n","Epoch 7/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - loss: 0.2195 - val_loss: 0.1343\n","Epoch 8/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - loss: 0.2178 - val_loss: 0.1339\n","Epoch 9/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - loss: 0.2052 - val_loss: 0.1330\n","Epoch 10/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - loss: 0.2036 - val_loss: 0.1396\n","Epoch 11/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - loss: 0.2062 - val_loss: 0.1342\n","Epoch 12/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - loss: 0.1950 - val_loss: 0.1374\n","Epoch 13/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - loss: 0.1934 - val_loss: 0.1343\n","Epoch 14/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - loss: 0.1997 - val_loss: 0.1318\n","Epoch 15/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - loss: 0.1928 - val_loss: 0.1322\n","Epoch 16/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - loss: 0.1883 - val_loss: 0.1259\n","Epoch 17/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - loss: 0.1903 - val_loss: 0.1272\n","Epoch 18/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - loss: 0.1825 - val_loss: 0.1320\n","Epoch 19/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - loss: 0.1805 - val_loss: 0.1266\n","Epoch 20/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - loss: 0.1836 - val_loss: 0.1256\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x373445a30>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Step 4: Build & Train Teacher Model (Dropout AE)\n","input_dim = X_train.shape[1]\n","inp = Input(shape=(input_dim,))\n","x = Dense(64, activation='relu')(inp)\n","x = Dropout(0.2)(x)\n","x = Dense(32, activation='relu')(x)\n","x = Dropout(0.2)(x)\n","encoded = Dense(16, activation='relu')(x)\n","x = Dense(32, activation='relu')(encoded)\n","x = Dropout(0.2)(x)\n","x = Dense(64, activation='relu')(x)\n","teacher_out = Dense(input_dim, activation='linear')(x)\n","teacher = Model(inp, teacher_out)\n","teacher.compile(optimizer=Adam(0.001), loss='mse')\n","teacher.fit(X_train, X_train, epochs=20, batch_size=256, validation_split=0.1, verbose=1)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m8570/8570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171us/step\n","\u001b[1m2837/2837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170us/step\n"]}],"source":["# Step 5: Teacher Reconstructions\n","T_train = teacher.predict(X_train)\n","T_test = teacher.predict(X_test)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Step 6: Build Student Model (Smaller AE)\n","def build_student():\n","    inp_s = Input(shape=(input_dim,))\n","    x = Dense(32, activation='relu')(inp_s)\n","    encoded_s = Dense(16, activation='relu')(x)\n","    x = Dense(32, activation='relu')(encoded_s)\n","    out_s = Dense(input_dim, activation='linear')(x)\n","    return Model(inp_s, out_s)\n","\n","student = build_student()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - functional_4_loss: 0.3321 - loss: 0.6676 - val_functional_4_loss: 0.0756 - val_loss: 0.1868\n","Epoch 2/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520us/step - functional_4_loss: 0.0712 - loss: 0.1691 - val_functional_4_loss: 0.0587 - val_loss: 0.1303\n","Epoch 3/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - functional_4_loss: 0.0589 - loss: 0.1279 - val_functional_4_loss: 0.0550 - val_loss: 0.1110\n","Epoch 4/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - functional_4_loss: 0.0570 - loss: 0.1124 - val_functional_4_loss: 0.0518 - val_loss: 0.0996\n","Epoch 5/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - functional_4_loss: 0.0524 - loss: 0.0995 - val_functional_4_loss: 0.0527 - val_loss: 0.0940\n","Epoch 6/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - functional_4_loss: 0.0517 - loss: 0.0930 - val_functional_4_loss: 0.0525 - val_loss: 0.0887\n","Epoch 7/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - functional_4_loss: 0.0504 - loss: 0.0860 - val_functional_4_loss: 0.0520 - val_loss: 0.0862\n","Epoch 8/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - functional_4_loss: 0.0518 - loss: 0.0861 - val_functional_4_loss: 0.0515 - val_loss: 0.0812\n","Epoch 9/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - functional_4_loss: 0.0508 - loss: 0.0817 - val_functional_4_loss: 0.0502 - val_loss: 0.0784\n","Epoch 10/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - functional_4_loss: 0.0498 - loss: 0.0780 - val_functional_4_loss: 0.0526 - val_loss: 0.0795\n","Epoch 11/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - functional_4_loss: 0.0501 - loss: 0.0771 - val_functional_4_loss: 0.0515 - val_loss: 0.0760\n","Epoch 12/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - functional_4_loss: 0.0499 - loss: 0.0758 - val_functional_4_loss: 0.0583 - val_loss: 0.0854\n","Epoch 13/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - functional_4_loss: 0.0530 - loss: 0.0789 - val_functional_4_loss: 0.0521 - val_loss: 0.0752\n","Epoch 14/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - functional_4_loss: 0.0500 - loss: 0.0728 - val_functional_4_loss: 0.0512 - val_loss: 0.0730\n","Epoch 15/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - functional_4_loss: 0.0515 - loss: 0.0738 - val_functional_4_loss: 0.0519 - val_loss: 0.0718\n","Epoch 16/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - functional_4_loss: 0.0519 - loss: 0.0727 - val_functional_4_loss: 0.0522 - val_loss: 0.0716\n","Epoch 17/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - functional_4_loss: 0.0523 - loss: 0.0723 - val_functional_4_loss: 0.0538 - val_loss: 0.0718\n","Epoch 18/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - functional_4_loss: 0.0526 - loss: 0.0713 - val_functional_4_loss: 0.0534 - val_loss: 0.0697\n","Epoch 19/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - functional_4_loss: 0.0532 - loss: 0.0700 - val_functional_4_loss: 0.0542 - val_loss: 0.0687\n","Epoch 20/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - functional_4_loss: 0.0539 - loss: 0.0687 - val_functional_4_loss: 0.0543 - val_loss: 0.0671\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x3249beae0>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Step 7: Distillation Training\n","gamma = 0.5  # distillation weight\n","inp_s = student.input\n","stud_out = student(inp_s)\n","distill = Model(inp_s, [stud_out, stud_out])  # two identical outputs\n","distill.compile(\n","    optimizer=Adam(0.001),\n","    loss=['mse','mse'],\n","    loss_weights=[1.0, gamma]\n",")\n","distill.fit(\n","    X_train, [X_train, T_train],\n","    epochs=20, batch_size=256,\n","    validation_split=0.1, verbose=1\n",")\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m2837/2837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163us/step\n","Confusion Matrix: [[64781  3776]\n"," [ 1079 21136]]\n","              precision    recall  f1-score   support\n","\n","      Normal       0.98      0.94      0.96     68557\n","      Attack       0.85      0.95      0.90     22215\n","\n","    accuracy                           0.95     90772\n","   macro avg       0.92      0.95      0.93     90772\n","weighted avg       0.95      0.95      0.95     90772\n","\n","FPR: 0.05507825604971046 FNR: 0.04857078550528922\n","ROC-AUC: 0.988282251360906\n"]}],"source":["# Step 8: Evaluate Student Model\n","S_pred = student.predict(X_test)\n","errors_s = np.mean((X_test - S_pred)**2, axis=1)\n","from sklearn.metrics import precision_recall_curve\n","prec_s, rec_s, thr_s = precision_recall_curve(y_test, errors_s)\n","f1_s = 2*(prec_s*rec_s)/(prec_s+rec_s+1e-8)\n","best_thr_s = thr_s[np.argmax(f1_s)]\n","y_pred_s = (errors_s > best_thr_s).astype(int)\n","cm = confusion_matrix(y_test, y_pred_s)\n","print('Confusion Matrix:', cm)\n","print(classification_report(y_test, y_pred_s, target_names=['Normal','Attack']))\n","tn, fp, fn, tp = cm.ravel()\n","print('FPR:', fp/(fp+tn), 'FNR:', fn/(fn+tp))\n","print('ROC-AUC:', roc_auc_score(y_test, errors_s))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":2}

{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Comparative Intrusion Detection with Multiple Autoencoder Architectures\n","This notebook trains and compares two different autoencoder structures on the UNSW-NB15 dataset, and reports detailed metrics for both normal and attack classes."]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# Step 1: Imports\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    confusion_matrix, classification_report, precision_recall_curve\n",")\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# Step 2: Load and Split Data\n","df = pd.read_csv(\"UNSW-NB15P-MM-SAMPLE.csv\")\n","Dn = df[df['Class'] == 0].drop(columns=['Class'])\n","Da = df[df['Class'] == 1].drop(columns=['Class'])\n","Dntr, Dnts = train_test_split(Dn, test_size=0.2, random_state=42)\n","Dts = pd.concat([Dnts, Da], ignore_index=True)\n","Dts_labels = np.array([0]*len(Dnts) + [1]*len(Da))"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["# Step 3: Normalize Features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(Dntr)\n","X_test = scaler.transform(Dts)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["# Step 4: Define Autoencoder Builder\n","def build_autoencoder(layer_sizes, dropout_rate=None):\n","    input_dim = X_train.shape[1]\n","    inp = Input(shape=(input_dim,))\n","    x = inp\n","    # Encoder\n","    for size in layer_sizes:\n","        x = Dense(size, activation='relu')(x)\n","        if dropout_rate:\n","            x = Dropout(dropout_rate)(x)\n","    # Decoder (reverse order)\n","    for size in layer_sizes[::-1][1:]:\n","        x = Dense(size, activation='relu')(x)\n","        if dropout_rate:\n","            x = Dropout(dropout_rate)(x)\n","    out = Dense(input_dim, activation='linear')(x)\n","    model = Model(inp, out)\n","    model.compile(optimizer=Adam(0.001), loss='mse')\n","    return model"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# Step 5: Instantiate Models\n","model1 = build_autoencoder([32, 16])                     # Simple 32-16-32\n","model2 = build_autoencoder([64, 32, 16], dropout_rate=0.2)  # Deeper with dropout"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Model 1...\n","Epoch 1/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450us/step - loss: 0.5417 - val_loss: 0.1367\n","Epoch 2/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.1112 - val_loss: 0.0844\n","Epoch 3/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.0751 - val_loss: 0.0628\n","Epoch 4/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.0574 - val_loss: 0.0514\n","Epoch 5/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.0482 - val_loss: 0.0455\n","Epoch 6/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.0435 - val_loss: 0.0400\n","Epoch 7/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.0397 - val_loss: 0.0367\n","Epoch 8/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - loss: 0.0360 - val_loss: 0.0354\n","Epoch 9/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.0372 - val_loss: 0.0327\n","Epoch 10/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 0.0336 - val_loss: 0.0308\n","Epoch 11/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.0320 - val_loss: 0.0303\n","Epoch 12/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.0332 - val_loss: 0.0299\n","Epoch 13/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.0284 - val_loss: 0.0257\n","Epoch 14/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.0265 - val_loss: 0.0240\n","Epoch 15/15\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - loss: 0.0236 - val_loss: 0.0231\n","Training Model 2...\n","Epoch 1/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - loss: 0.7362 - val_loss: 0.3677\n","Epoch 2/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - loss: 0.4563 - val_loss: 0.3309\n","Epoch 3/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - loss: 0.4186 - val_loss: 0.2940\n","Epoch 4/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - loss: 0.4047 - val_loss: 0.2719\n","Epoch 5/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - loss: 0.3939 - val_loss: 0.2666\n","Epoch 6/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - loss: 0.3688 - val_loss: 0.2671\n","Epoch 7/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - loss: 0.3608 - val_loss: 0.2486\n","Epoch 8/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756us/step - loss: 0.3639 - val_loss: 0.2681\n","Epoch 9/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - loss: 0.3497 - val_loss: 0.2411\n","Epoch 10/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - loss: 0.3461 - val_loss: 0.2379\n","Epoch 11/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - loss: 0.3442 - val_loss: 0.2360\n","Epoch 12/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - loss: 0.3366 - val_loss: 0.2401\n","Epoch 13/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - loss: 0.3309 - val_loss: 0.2344\n","Epoch 14/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - loss: 0.3296 - val_loss: 0.2255\n","Epoch 15/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - loss: 0.3318 - val_loss: 0.2212\n","Epoch 16/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - loss: 0.3386 - val_loss: 0.2218\n","Epoch 17/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - loss: 0.3230 - val_loss: 0.2172\n","Epoch 18/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - loss: 0.3314 - val_loss: 0.2158\n","Epoch 19/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - loss: 0.3169 - val_loss: 0.2129\n","Epoch 20/20\n","\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - loss: 0.3365 - val_loss: 0.2448\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x38f1e4ef0>"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["# Step 6: Train Models\n","print('Training Model 1...')\n","model1.fit(X_train, X_train, epochs=15, batch_size=256, validation_split=0.1, verbose=1)\n","print('Training Model 2...')\n","model2.fit(X_train, X_train, epochs=20, batch_size=256, validation_split=0.1, verbose=1)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["# Step 7: Evaluation Function Returns Full Report\n","def evaluate_model(model, X_train, X_test, y_test):\n","    # Predict and compute reconstruction error\n","    X_pred = model.predict(X_test)\n","    errors = np.mean((X_test - X_pred)**2, axis=1)\n","    # Optimal threshold via F1\n","    prec, rec, thr = precision_recall_curve(y_test, errors)\n","    f1_scores = 2 * (prec * rec) / (prec + rec + 1e-8)\n","    best_thr = thr[np.argmax(f1_scores)]\n","    y_pred = (errors > best_thr).astype(int)\n","    # Confusion matrix and report\n","    cm = confusion_matrix(y_test, y_pred)\n","    report = classification_report(y_test, y_pred, target_names=['Normal','Attack'])\n","    tn, fp, fn, tp = cm.ravel()\n","    fpr = fp / (fp + tn)\n","    fnr = fn / (fn + tp)\n","    return cm, report, {'FPR': fpr, 'FNR': fnr}"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","=== AE_32-16 ===\n","\u001b[1m2837/2837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162us/step\n","Confusion Matrix:\n"," [[63226  5331]\n"," [ 1863 20352]]\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","      Normal       0.97      0.92      0.95     68557\n","      Attack       0.79      0.92      0.85     22215\n","\n","    accuracy                           0.92     90772\n","   macro avg       0.88      0.92      0.90     90772\n","weighted avg       0.93      0.92      0.92     90772\n","\n","False Positive Rate: 0.07776011202357162\n","False Negative Rate: 0.08386225523295071\n","\n","=== AE_64-32-16_dropout ===\n","\u001b[1m2837/2837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174us/step\n","Confusion Matrix:\n"," [[64751  3806]\n"," [   76 22139]]\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","      Normal       1.00      0.94      0.97     68557\n","      Attack       0.85      1.00      0.92     22215\n","\n","    accuracy                           0.96     90772\n","   macro avg       0.93      0.97      0.95     90772\n","weighted avg       0.96      0.96      0.96     90772\n","\n","False Positive Rate: 0.05551584812637659\n","False Negative Rate: 0.00342111186135494\n"]}],"source":["# Step 8: Evaluate and Display Detailed Results\n","for name, model in [('AE_32-16', model1), ('AE_64-32-16_dropout', model2)]:\n","    print(f\"\\n=== {name} ===\")\n","    cm, report, rates = evaluate_model(model, X_train, X_test, Dts_labels)\n","    print(\"Confusion Matrix:\\n\", cm)\n","    print(\"\\nClassification Report:\\n\", report)\n","    print(\"False Positive Rate:\", rates['FPR'])\n","    print(\"False Negative Rate:\", rates['FNR'])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":2}
